---
title: "Human Activity Recognition Project"
author: "Adam J"
date: '2020-07-17'
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
set.seed(12321)
library(dplyr)
library(ggplot2)
library(caret)
```


## Overview
The puspose of this project is to answer the question, can one classify the correctness of a physical activity based on measurement data from accelerometer placed on the subjects body, given a data set containing labeled measurements from all different classes?

Summary of the project. What is the purpose, what questions is of interest to answer, what was done in order to answer them? What was the main results and what conclusions can or can't we draw from them?

## Preprocessing
Clean the data 

 - Are there NA values? 
 - Is the data skewed? 

Create training, validation and test sets.

```{r}
trainDat <- read.csv("trainDat.csv")
testDat <- read.csv("testDat.csv")

# Select columns with NA values, these are the variables which aggregate the other variables per time window
dat <- trainDat[, colSums(is.na(trainDat)) != 0]

# Append the class variable along with the seven first variables in trainDat
dat <- data.frame(trainDat[,(1:7)], dat, trainDat$classe)

# Rename the class variable
names(dat)[dim(dat)[2]] <- "classe"

# Filter out observations containing aggregated window information only
dat <- filter(dat, new_window == "yes")

preProcDat <- dat[, -(1:7)]

```

## Data Exploration
Here we explore the data and look for pattern and think of potential candidates for model selection. 

 - Is there a nonlinear or linear relationship between the outcome (activity class) and the predictors (measurements from accelerometers)?
 - What is the approximate distribution of the variables in the dataset?

## Model selection
Investigate different models and how they compare on the validation set after having been trained on the training set.

## Model evaluation
Do a final evaluation on the selected model by testing to predict on unseen data from the test set.

## Discussion & Conclusion
Discuss the resulting accuracy or similar measures achieved in the final model evaluation and conclude if it is sufficient to answer the question of interest and if the purpose of the project was fulfilled.




